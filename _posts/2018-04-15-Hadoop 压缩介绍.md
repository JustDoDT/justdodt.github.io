### 压缩简介

在大数据领域，压缩是无法避免的话题，比如，在电商系统中，用户的行为数据越来越大，当达到一定的量时，将会面临着，怎么快速地处理这些数据。
在Hadoop 生态系统中，对数据进行压缩处理使得提高我们的数据处理效率，如何选择压缩和使用压缩？

**压缩**

压缩是把数据“减少”的过程。

**解压缩**

将压缩过后的数据转换成原始数据的过程。

**为什么使用压缩**

1. 减少文件大小
2. 节省磁盘空间
3. 增加网络传输的效率

### 常用的压缩技术

#### 无损压缩(Lossless compression)
压缩和解压缩的过程中没有数据丢失

**问题：在压缩的过程中，多余的数据去了哪里？**

多余的数据必然是冗余的数据，借助一些算法，冗余的数据在压缩的过程中会被移除
在解压的过程中，借助同样的算法，再把它自动的补充上来
适用场景：
用户行为日志
如果是用来做计费的，数据必然是不能丢的，丢了公司就少盈利了

#### 有损压缩(Lossy compression)

有损压缩(对于图片、视频的处理，可以采用有损压缩)
压缩过后和压缩之前的数据有损失
图片和视频丢掉几帧，凭肉眼是很难被区分出来的
**好处:**
技术成本低，压缩率 压缩比非常高 能够更节省空间，而且压缩的时间也非常短


### 压缩场景(以MapReduce为例)

从3个角度来看：输入，中间，输出

#### 输入
如果输入文件是经过压缩的，那么数据压缩过后所占用的HDFS的空间就会少很多，通常情况下，也就意味着读取数据所耗费的时间也就比较少，但是，当CPU处于高负载的情况
，所读取的时间也会很长。

MapReduce/Hive/Spark这些框架是可以读取压缩文件的，它们会自动进行解压
这些计算框架在读取文件之后，具备自动解压文件的功能
数据有没有压缩，分布式处理框架都是能自动识别的，并不需要去做额外的东西

涉及到一个问题：

不同的压缩方式它的codec是不一样的
比如：GzipCodec…
中间
以MapReduce来看，Map过程之后是有输出的
如果在做shuffle之前，对数据使用压缩，必然是会减少磁盘空间，
而在shuffle过程因为体积减少，传输效率也是会提高的
建议：中间过程也是采用压缩

输出
对于输出也是同理的，如果对于输出的文件是作为历史文件的，更应该使用压缩，而且需要选用压缩比非常高的压缩方式
这样历史数据，占用空间肯定少了

总结：
对于上述三点，不管哪一步，都建议采用压缩，
前提：CPU(如果CPU都不够用，就别采用压缩了)

压缩注意事项
从上述的来看，压缩能带来的好处有：

节省存储空间、加速数据传输、减少磁盘与网络的IO
这些对于大数据的执行性能是有改善的
但是压缩/解压缩的过程，CPU的利用率是很高的
在使用的时候，是针对集群的状况来做取舍的，如下图所示：





























